# üß† RAG System ‚Äî Retrieval-Augmented Generation

A full-stack RAG system that retrieves relevant documents from a vector database and generates grounded responses using Google Gemini. Features **LangGraph orchestration**, **strict structured routing/planning/validation**, **SSE streaming**, a **React chat interface**, and a **built-in evaluation framework**.

> Built with FastAPI, LangGraph, Neon PostgreSQL (`pgvector`), Google Gemini, and React.

## Architecture

```mermaid
flowchart TB
    subgraph Frontend["Frontend (React + Vite)"]
        UI["Chat UI"]
        SSE["SSE Stream Reader"]
    end

    subgraph Backend["Backend (FastAPI)"]
        API["API Endpoints"]
        EMB["Embedding Service<br/>Gemini Embedding"]
        VS["Vector Store<br/>Neon pgvector"]
        LLM["LLM Service<br/>Gemini 2.0 Flash"]
        RAG["LangGraph Orchestrator"]
    end

    subgraph Data["Data Layer"]
        DOCS["Source Documents<br/>JSON now, multi-format later"]
        NEON[("Neon PostgreSQL<br/>Relational + pgvector")]
    end

    UI -->|"User Query"| API
    API --> RAG
    RAG --> EMB -->|"Query Embedding"| VS
    VS -->|"Top-K Docs"| RAG
    RAG -->|"Context + Query"| LLM
    LLM -->|"SSE Chunks"| API
    API -->|"Streaming Response"| SSE --> UI

    DOCS -->|"Ingest & Chunk"| EMB
    EMB -->|"Store Embeddings"| NEON
    VS <-->|"Search"| NEON

    style Frontend fill:#1a1a2e,stroke:#8b5cf6,color:#fff
    style Backend fill:#16213e,stroke:#3b82f6,color:#fff
    style Data fill:#0f3460,stroke:#10b981,color:#fff
```

## End-to-End Flow (Roadmap)

```mermaid
flowchart TD
    A["Data Sources"] --> B["Data Processing<br/>parse -> chunk -> metadata"]
    B --> C["Database Layer<br/>Vector + Relational"]
    C --> D["User Query"]
    D --> E["Reasoning Engine<br/>plan + route + tools"]
    E --> F["Multi-Agent System"]
    F --> G["Database Retrieval"]
    G --> H["Human Validation (optional)"]
    H --> I["Evaluation Layer"]
    I -. feedback loop .-> A
```

### Implementation Status

- [x] Data Sources (Completed)
- [x] Data Processing (Completed)
- [x] Database Layer (Completed)
- [x] User Query (Guard implemented)
- [x] Reasoning Engine (plan + route + tools)
- [ ] Multi-Agent System
- [x] Database Retrieval (agentic retrieval loop)
- [ ] Human Validation (optional)
- [/] Evaluation Layer + feedback loop (Framework ready)

### Data Sources & Processing (Current Milestone)

- **Status**: ‚úÖ Completed for current scope
- **Current source**: `backend/data/documents/SQuAD-small.json`
- **Processing flow**:
  1. Parse source file
  2. Split content into chunks
  3. Attach metadata per chunk
  4. Send chunks to embedding + database ingestion path
- **Notes**: This milestone is intentionally scoped to data input and processing only. Remaining layers are planned for future milestones.

### User Query (Current Guard)

- **Status**: ‚úÖ Basic guard implemented
- **What is implemented now**:
  1. Normalize input by trimming and collapsing repeated whitespace
  2. Reject empty or whitespace-only query input
  3. Keep explicit request bounds (`max_length=1000`, `top_k` range)
- **Implementation**: `backend/services/query_guard.py` + `QueryRequest` validator in `backend/models.py`
- **Scope note**: Rate limits, intent gating, and confidence thresholds are planned in later milestones.

### Reasoning Engine (Current Milestone)

- **Status**: ‚úÖ Implemented (Phase 1)
- **What is implemented now**:
  1. **LangGraph state machine** with explicit nodes:
     `ingest_query -> query_router -> planner -> tool_orchestrator -> writer -> validation_router -> decision_node -> finalize_response`
  2. **Strict structured control nodes** (Router/Planner/Validator) with schema validation and retry on schema failures.
  3. **Supported routes**: `direct`, `rag_simple`, `clarify`, `unsafe`.
  4. **Supported tools**: `vector_search`, `rerank`.
  5. **Validation loop**: `pass | revise | replan | fail_safe` with one retry and deterministic fail-safe fallback.
  6. **Safety parity across endpoints**: `/query` and `/query/stream` both run the same validation contract before returning user-visible answers.
- **Implementation**:
  - `backend/services/rag.py`
  - `backend/services/llm.py`
  - `backend/services/vector_store.py`
  - `backend/tests/test_rag_pipeline.py`
- **Scope note**: Multi-agent routing and additional external tools are intentionally out of scope for this milestone.

### Database Retrieval (Agentic Retrieval Loop)

- **Status**: ‚úÖ Implemented for current scope
- **What is implemented now**:
  1. **Planner-directed retrieval loop** executes `vector_search` and optional `rerank` steps from plan budgets.
  2. **Evidence extraction and ranking** converts vector results into chunk-level evidence with relevance scores.
  3. **Agentic replan behavior** triggers when retrieval returns no evidence and retries once before fail-safe.
  4. **Circuit-breaker guard** fails safe when tool failure ratio exceeds threshold.
  5. **Endpoint parity**: `/query` and `/query/stream` both use the same validated graph result before responding.
- **Implementation**:
  - `backend/services/rag.py`
  - `backend/services/vector_store.py`
  - `backend/tests/test_rag_pipeline.py`
  - `backend/tests/test_vector_store.py`
- **Scope note**: This covers the single-agent retrieval loop over the active corpus. Multi-agent retrieval coordination remains a separate milestone.

### Evaluation Layer & Feedback Loop (Current Milestone)

- **Status**: ‚úÖ Framework implemented
- **What is implemented now**:
  1. **Runner**: Automated execution engine (`runner.py`)
  2. **Judges**: LLM-based judges for Groundedness and Quality (`judges.py`)
  3. **Gates**: CI/CD quality gates with strict thresholds (`check_gates.py`)
  4. **Reports**: Detailed JSON/HTML artifacts for each run
- **Implementation**: `backend/evaluation/` directory
- **Scope note**: Feedback loop to Data Sources is currently manual. Automated retraining/re-indexing loops are planned for future milestones.

## Database Layer

The system uses a **Hybrid RAG** storage architecture, leveraging **Neon PostgreSQL** for both vector and relational data.

### 1. Vector Store (Embedding Retrieval)
- **Implementation**: Neon PostgreSQL with `pgvector` extension.
- **Purpose**: High-performance similarity search for document chunks.
- **Index**: HNSW (Hierarchical Navigable Small World) for efficient approximate nearest neighbor search.
- **Dimensionality**: 768 (matching Gemini Embedding 001).

### 2. Relational Database (Future Proofing)
- **Status**: Provisioned but currently minimal usage.
- **Capabilities**: Ready for structured metadata, queryable logs, and application state.
- **Current State**: The system is designed to be easily extensible to store chat history, user feedback, and detailed telemetry in relational tables side-by-side with the vectors.

### Key Features

- üîç **Semantic search** ‚Äî Gemini embeddings with Neon PostgreSQL (`pgvector`)
- üß≠ **LangGraph state machine** ‚Äî Routed execution with conditional edges and retry paths
- ‚úÖ **Strict structured control nodes** ‚Äî Schema-enforced Router/Planner/Validator outputs
- ‚ö° **Streaming** ‚Äî Token-by-token SSE streaming for real-time responses
- üìä **Evaluation** ‚Äî Built-in metrics framework (precision, recall, faithfulness)
- üé® **Chat UI** ‚Äî Dark-mode React frontend with source citations
- üê≥ **Docker Compose** ‚Äî One-command full-stack deployment
- üöÄ **CI/CD** ‚Äî Automated deploy to Cloud Run (backend) and Firebase Hosting (frontend)

## RAG Plan Status

- [x] Phase 1 MVP checklist complete (QueryState, router, planner, tool_orchestrator, writer, relevance/groundedness validator, single retry loop)
- [x] LangGraph runtime integrated for orchestration
- [x] Strict schema-based Router/Planner/Validator output wired through Gemini JSON mode
- [x] Legacy SQLModel SQuAD ingestion path retained as an optional pipeline (not in main API runtime)
- [ ] Phase 2 (agent layer, completeness and citation checks, richer failure policies)
- [ ] Phase 3 (observability dashboards, caching/rate limiting, latency/cost tuning)

---

## Quick Start

### Option 1: Docker Compose (Recommended)

```bash
# 1. Clone and configure
git clone <repo-url> && cd coding-exercise
cp backend/.env.example backend/.env
# Edit backend/.env ‚Äî set GEMINI_API_KEY and DATABASE_URL

# 2. Start everything
docker-compose up --build

# 3. Ingest documents
curl -X POST http://localhost:8000/ingest

# 4. Open the UI
open http://localhost:5173
```

### Option 2: Local Development

#### Backend (Terminal 1)

```bash
cd backend
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Configure your Gemini API key
cp .env.example .env
# Edit .env and set GEMINI_API_KEY + DATABASE_URL

# Ingest the source documents into Neon PostgreSQL (pgvector)
# Option A: Use the helper script (Recommended)
python scripts/ingest.py

# Option B: Use curl directly
# curl -X POST http://localhost:8000/ingest

# Start the backend server
uvicorn main:app --reload
# ‚úÖ Backend running at http://localhost:8000
```

#### Frontend (Terminal 2)

```bash
cd frontend
npm install
# Optional: override API base for direct backend URL deployments
# export VITE_API_BASE=https://your-backend-host
npm run dev
# ‚úÖ Frontend running at http://localhost:5173
```

> **Note:** Frontend requests default to `/api`.
> - Local dev (Vite): `/api` is proxied to `http://localhost:8000`
> - Docker (Nginx): `/api` is proxied to `http://backend:8000`
> - Direct-backend deployments: set `VITE_API_BASE` at build time

---

## API Endpoints

| Method | Path | Description |
|--------|------|-------------|
| `GET` | `/health` | Health check + model status |
| `POST` | `/query` | RAG query (JSON response) |
| `POST` | `/query/stream` | RAG query (SSE streaming) |
| `GET` | `/documents` | List indexed documents |
| `POST` | `/ingest` | Ingest documents from disk |

### Example Query

```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Why is centering a div so hard?", "top_k": 3}'
```

---

## GitHub Actions Deploy Secrets

For backend auto-deploy (`.github/workflows/deploy-backend.yml`), set these repository secrets:

- `GCP_PROJECT_ID`
- `GCP_SA_KEY`
- `GEMINI_API_KEY`
- `DATABASE_URL` (Neon/Postgres connection string)

Without `DATABASE_URL`, Cloud Run startup will fail when `VectorStoreService` initializes.

---

## üìä Evaluation & Quality Gates

The project includes a custom evaluation framework located in `backend/evaluation/`. It replaces heavier libraries like RAGAS with transparent, strict-schema LLM judges and heuristic metrics.

### 1. Running Evaluations

Run limits or full sweeps using the runner CLI entrypoint:

```bash
cd backend
# Run full evaluation (retrieval + LLM judges) with top-k=5
python -m evaluation.runner --mode full_rag_with_judges --top-k 5 --limit 10

# Run retrieval-only (faster, for experimenting with embeddings/chunking)
python -m evaluation.runner --mode retrieval_only --top-k 5
```

> You can also use `python -m evaluation.evaluate ...`; both entrypoints call the same evaluation runner.

### 2. Checking Quality Gates

CI/CD pipelines enforce quality standards using `gates.yaml`. This script fails the build if metrics drop below baselines (regression) or absolute thresholds.

```bash
python -m evaluation.check_gates --scope full
```

### 3. Reports & Artifacts

All runs generate artifacts in `backend/evaluation/reports/`:
- **`retrieval_metrics.json`**: Precision, Recall, MRR, NDCG.
- **`answer_metrics.json`**: Groundedness, Quality, Hallucination Rate.
- **`latency_cost_metrics.json`**: P95 latency, cost per query, token usage.
- **`examples_failed.jsonl`**: Specific cases that failed gates or retrieval.

---

## Tech Stack

| Component | Technology |
|-----------|-----------|
| Backend | Python, FastAPI, Uvicorn, LangGraph |
| Vector DB | Neon PostgreSQL + `pgvector` |
| Embeddings | Gemini Embedding (`gemini-embedding-001`) |
| LLM | Google Gemini 2.0 Flash |
| Frontend | React 18, Vite |
| Infra | Docker Compose, Nginx, Cloud Run, Firebase Hosting |

## Design Decisions

1. **Neon PostgreSQL + pgvector as a unified store** ‚Äî One managed database for both relational data and vector search, simplifying deployment and operations.

2. **Gemini Embeddings over sentence-transformers** ‚Äî Eliminates the ~2 GB PyTorch dependency, keeping Docker images small. Uses `gemini-embedding-001` with `output_dimensionality=768` via the same API key already needed for generation.

3. **SSE over WebSockets** ‚Äî Simpler to implement, works through proxies, and is the standard for LLM streaming (used by ChatGPT, Claude, etc.).

4. **Custom evaluation over RAGAS** ‚Äî Lightweight, no heavy dependencies, and more transparent. Each metric is <30 lines and easy to understand.

---

## Running Tests

```bash
# From repo root (recommended)
python -m pytest backend/tests -v

# Or from backend/
cd backend
python -m pytest tests/ -v
```

---

## Project Structure

```
coding-exercise/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                  # FastAPI endpoints (query, stream, ingest, health)
‚îÇ   ‚îú‚îÄ‚îÄ config.py                # Pydantic settings from .env
‚îÇ   ‚îú‚îÄ‚îÄ models.py                # Request/response schemas
‚îÇ   ‚îú‚îÄ‚îÄ models_sql.py            # SQLModel schema definitions
‚îÇ   ‚îú‚îÄ‚îÄ database.py              # Database connection logic
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile               # Multi-stage backend container
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh                # Manual Cloud Run deploy script
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt         # Python dependencies (dev)
‚îÇ   ‚îú‚îÄ‚îÄ requirements-prod.txt    # Python dependencies (production)
‚îÇ   ‚îú‚îÄ‚îÄ check_embedding_dim.py   # Embedding dimension validator
‚îÇ   ‚îú‚îÄ‚îÄ .env.example             # Environment variable template
‚îÇ   ‚îú‚îÄ‚îÄ .dockerignore            # Docker build exclusions
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embedding.py         # Gemini embedding service (gemini-embedding-001)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py      # Neon PostgreSQL pgvector operations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ llm.py               # Gemini LLM integration + strict structured output helpers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ query_guard.py       # User-query normalization and validation helpers
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag.py               # LangGraph RAG pipeline orchestration
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingest.py            # Document chunking & ingestion
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingest_squad.py      # SQuAD dataset ingestion
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ verify_ingestion.py  # Ingestion verification script
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ documents/           # Source files (currently JSON corpus)
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py          # Evaluation runner
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py           # Precision, recall, faithfulness metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_queries.json    # 12 curated test queries
‚îÇ   ‚îî‚îÄ‚îÄ tests/
‚îÇ       ‚îú‚îÄ‚îÄ conftest.py          # Pytest fixtures
‚îÇ       ‚îú‚îÄ‚îÄ test_api.py          # API integration tests
‚îÇ       ‚îú‚îÄ‚îÄ test_rag.py          # RAG evaluation tests
‚îÇ       ‚îú‚îÄ‚îÄ test_rag_pipeline.py # RAG pipeline tests
‚îÇ       ‚îî‚îÄ‚îÄ test_vector_store.py # Vector store unit tests
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ index.html               # Entry point
‚îÇ   ‚îú‚îÄ‚îÄ vite.config.js           # Vite config + API proxy
‚îÇ   ‚îú‚îÄ‚îÄ package.json             # Node dependencies
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile               # Multi-stage build (Vite ‚Üí Nginx)
‚îÇ   ‚îú‚îÄ‚îÄ nginx.conf               # Nginx config for SPA + API proxy
‚îÇ   ‚îú‚îÄ‚îÄ firebase.json            # Firebase Hosting configuration
‚îÇ   ‚îú‚îÄ‚îÄ .firebaserc              # Firebase project binding
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ main.jsx             # React entry
‚îÇ       ‚îú‚îÄ‚îÄ App.jsx              # Main app + SSE streaming logic
‚îÇ       ‚îú‚îÄ‚îÄ index.css            # Global styles (dark theme)
‚îÇ       ‚îî‚îÄ‚îÄ components/
‚îÇ           ‚îú‚îÄ‚îÄ ChatInterface.jsx   # Message list + empty state
‚îÇ           ‚îú‚îÄ‚îÄ Message.jsx         # Individual message rendering
‚îÇ           ‚îú‚îÄ‚îÄ QueryInput.jsx      # Auto-resizing textarea input
‚îÇ           ‚îî‚îÄ‚îÄ SourceDocuments.jsx # Retrieved sources panel
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îú‚îÄ‚îÄ deploy-backend.yml   # CI/CD: Backend ‚Üí Cloud Run
‚îÇ       ‚îî‚îÄ‚îÄ deploy-frontend.yml  # CI/CD: Frontend ‚Üí Firebase Hosting
‚îú‚îÄ‚îÄ docker-compose.yml           # Backend + Frontend orchestration
‚îî‚îÄ‚îÄ README.md
```
